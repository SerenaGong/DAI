{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "FILE_IN='../fixtures/test.csv'\n",
    "SCHEMA=StructType([\n",
    "    StructField('account_id', LongType(), False),\n",
    "    StructField('last_name', StringType(), False),\n",
    "    StructField('first_name', StringType(), False),\n",
    "    StructField('phone', StringType(), False),\n",
    "    StructField('address_1', StringType(), False),\n",
    "    StructField('address_2', StringType(), True),\n",
    "    StructField('city', StringType(), False),\n",
    "    StructField('state', StringType(), False),\n",
    "    StructField('postal_code', StringType(), False),\n",
    "    StructField('plan_id', StringType(), False),\n",
    "    StructField('foundation_id', StringType(), True),\n",
    "    StructField('joined_at', TimestampType(), False),\n",
    "    StructField('prev_balance', FloatType(), True),\n",
    "    StructField('adjustments', FloatType(), True),\n",
    "    StructField('prev_voice', IntegerType(), True),\n",
    "    StructField('prev_data', IntegerType(), True),\n",
    "    StructField('line', StringType(), False),\n",
    "    StructField('txn_type', StringType(), False),\n",
    "    StructField('txn_at', StringType(), False),\n",
    "    StructField('place', StringType(), True),\n",
    "    StructField('sent_recv', StringType(), True),\n",
    "    StructField('to_from', StringType(), True),\n",
    "    StructField('in_plan', IntegerType(), True),\n",
    "    StructField('in_network', IntegerType(), True),\n",
    "    StructField('mins', IntegerType(), True),\n",
    "    StructField('type_unit', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override default spark session var\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         #.config(\"spark.driver.cores\", \"2\")\n",
    "         .appName(\"read_csv\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('account_id', 'bigint'),\n",
       " ('last_name', 'string'),\n",
       " ('first_name', 'string'),\n",
       " ('phone', 'string'),\n",
       " ('address_1', 'string'),\n",
       " ('address_2', 'string'),\n",
       " ('city', 'string'),\n",
       " ('state', 'string'),\n",
       " ('postal_code', 'string'),\n",
       " ('plan_id', 'string'),\n",
       " ('foundation_id', 'string'),\n",
       " ('joined_at', 'timestamp'),\n",
       " ('prev_balance', 'float'),\n",
       " ('adjustments', 'float'),\n",
       " ('prev_voice', 'int'),\n",
       " ('prev_data', 'int'),\n",
       " ('line', 'string'),\n",
       " ('txn_type', 'string'),\n",
       " ('txn_at', 'string'),\n",
       " ('place', 'string'),\n",
       " ('sent_recv', 'string'),\n",
       " ('to_from', 'string'),\n",
       " ('in_plan', 'int'),\n",
       " ('in_network', 'int'),\n",
       " ('mins', 'int'),\n",
       " ('type_unit', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from sample CSV file, apply schema.\n",
    "df = (spark.read\n",
    "      .option(\"header\", \"false\")\n",
    "      #.option(\"mode\", \"DROPMALFORMED\")\n",
    "      #.option(\"inferSchema\", \"true\") \n",
    "      .schema(SCHEMA)\n",
    "      .csv(FILE_IN))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(account_id=1006461066240, last_name='Corgan', first_name='Cocktail', phone='3063434235', address_1='36328 Rachel Wall', address_2=None, city='Michellemouth', state='VI', postal_code='59957', plan_id='PLAN4000', foundation_id=None, joined_at=datetime.datetime(2007, 1, 9, 12, 46, 1), prev_balance=0.0, adjustments=0.0, prev_voice=1602, prev_data=1287192, line='4030133964', txn_type='VOC', txn_at='2017-12-27 19:46:57-08:00', place='INCOMI CL', sent_recv=None, to_from='4030133964', in_plan=1, in_network=0, mins=3, type_unit=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 57911\n"
     ]
    }
   ],
   "source": [
    "# count of rows in df\n",
    "print(\"count: {}\".format(df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14673"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter\n",
    "plan4000 = df.filter(df.plan_id == 'PLAN4000')\n",
    "plan4000.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter with sql\n",
    "df.createOrReplaceTempView('plans')\n",
    "plan4000 = spark.sql(\"SELECT account_id FROM plans where plan_id = 'PLAN4000'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan count: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Plan count: {}\".format(plan4000.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct Account IDs: 100\n"
     ]
    }
   ],
   "source": [
    "# select semantics (w/ distinct)\n",
    "plan4000 = df.select('account_id').distinct()\n",
    "print(\"Distinct Account IDs: {}\".format(plan4000.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+\n",
      "|  cnt| plan_id|\n",
      "+-----+--------+\n",
      "|19514|PLAN1000|\n",
      "|14673|PLAN4000|\n",
      "|11964|PLAN3000|\n",
      "|11760|PLAN2000|\n",
      "+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL aggregates\n",
    "plan_counts = spark.sql(\"\"\"\n",
    "    select \n",
    "        count(*) cnt, \n",
    "        plan_id \n",
    "    from \n",
    "        plans \n",
    "    group by \n",
    "        2 \n",
    "    order by \n",
    "        1 desc \n",
    "\"\"\")\n",
    "plan_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "| plan_id|  cnt|\n",
      "+--------+-----+\n",
      "|PLAN1000|19514|\n",
      "|PLAN3000|11964|\n",
      "|PLAN4000|14673|\n",
      "|PLAN2000|11760|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df aggregates\n",
    "plan_counts = (df.groupby(df.plan_id)\n",
    "               .agg(f.count(f.lit(1)).alias('cnt'))\n",
    "              )\n",
    "\n",
    "plan_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_counts = df.groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
